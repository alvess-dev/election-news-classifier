{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hODfjjsJK8uR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separarTreinoTeste(dfA):\n",
    "    dfB = pd.DataFrame()\n",
    "    dfC = pd.DataFrame()\n",
    "    for i in range (len(dfA)):\n",
    "        vetor = dfA.iloc[i, 0]\n",
    "        if (rd.random() > 0.8): # vai p teste\n",
    "            dfB = pd.concat([dfB, pd.DataFrame(data=[[vetor]], columns=['noticias'])], ignore_index=True)\n",
    "        else:\n",
    "            dfC = pd.concat([dfC, pd.DataFrame(data=[[vetor]], columns=['noticias'])], ignore_index=True)\n",
    "\n",
    "    return dfB, dfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepararDfTeste (dfA, dfB):\n",
    "    dados = []\n",
    "\n",
    "    # embaralha os dfs\n",
    "    dfEmbaralhado = pd.concat([dfA, dfB], ignore_index=True)\n",
    "    indices = list(dfEmbaralhado.index)\n",
    "    rd.shuffle(indices)\n",
    "    dfEmbaralhado = dfEmbaralhado.iloc[indices].reset_index(drop=True)\n",
    "    \n",
    "    # cria uma coluna pra tag\n",
    "    for i in range (len(dfEmbaralhado)):\n",
    "        news = dfEmbaralhado.iloc[i, 0]\n",
    "        tag = news[0]\n",
    "        news = news[1:]\n",
    "        dados.append([tag, news])\n",
    "\n",
    "    return pd.DataFrame(dados, columns=['tag', 'noticia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepararDfsTreino (dfF, dfR):\n",
    "    for i in range(len(dfF)):\n",
    "        noticia = dfF.iloc[i, 0]\n",
    "        noticia.remove('f')\n",
    "\n",
    "    for i in range(len(dfR)):\n",
    "        noticia = dfR.iloc[i, 0]\n",
    "        noticia.remove('r')\n",
    "\n",
    "    palavras = []\n",
    "    for i in range(len(dfF)):\n",
    "        vetor = dfF.iloc[i, 0]\n",
    "        for word in vetor:\n",
    "            palavras.append(word)\n",
    "    dfF = pd.DataFrame({'palavras': palavras})\n",
    "    dfF = dfF.groupby('palavras').size().reset_index(name='aparicoesFalsas')\n",
    "\n",
    "    palavras = []\n",
    "    for i in range(len(dfR)):\n",
    "        vetor = dfR.iloc[i, 0]\n",
    "        for word in vetor:\n",
    "            palavras.append(word)\n",
    "    dfR = pd.DataFrame({'palavras': palavras})\n",
    "    dfR = dfR.groupby('palavras').size().reset_index(name='aparicoesReais')\n",
    "\n",
    "    return dfF, dfR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "P4VNs4t3K8uU"
   },
   "outputs": [],
   "source": [
    "def evaluate(dfReal, dfFalso, noticiasTeste):\n",
    "    # Junta os dataframes e une as palavras\n",
    "    dfJunto = dfReal.merge(dfFalso, how='outer')\n",
    "\n",
    "    # Conta quantas palavras tem em uma e não tem na outra\n",
    "    nReal = dfJunto.loc[dfJunto['aparicoesReais'].isna(), 'palavras'].count()\n",
    "    nFalsa = dfJunto.loc[dfJunto['aparicoesFalsas'].isna(), 'palavras'].count()\n",
    "\n",
    "    # Preenche as palavras que não aparecem com 1\n",
    "    dfJunto.fillna(1, inplace=True)\n",
    "\n",
    "    # Soma as palavras com 0 aparições com 1 para evitar multiplicação por 0\n",
    "    dfJunto.loc[dfJunto['aparicoesReais'] > 1, 'aparicoesReais'] += 1\n",
    "    dfJunto.loc[dfJunto['aparicoesFalsas'] > 1, 'aparicoesFalsas'] += 1\n",
    "\n",
    "    # Soma o total de aparições\n",
    "    totalReal = dfJunto['aparicoesReais'].sum()\n",
    "    totalFalso = dfJunto['aparicoesFalsas'].sum()\n",
    "\n",
    "    # Balanceia a ordem de grandeza das aparições\n",
    "    dfJunto['aparicoesFalsas'] *= totalReal / totalFalso\n",
    "\n",
    "    # Faz o coeficiente de bray courtis\n",
    "    dfJunto['bc'] = abs(dfJunto['aparicoesReais'] - dfJunto['aparicoesFalsas']) / (dfJunto['aparicoesReais'] + dfJunto['aparicoesFalsas'])\n",
    "\n",
    "    # Limpa palavras com coeficiente menor que 0.3 (palavras com aparições equivalentes em ambos casos)\n",
    "    dfJunto = dfJunto.loc[dfJunto['bc'] > 0.3]\n",
    "\n",
    "    # Pega o total de aparições após NLP\n",
    "    tFalsas = dfJunto['aparicoesFalsas'].sum()\n",
    "    tReais = dfJunto['aparicoesReais'].sum()\n",
    "\n",
    "    # Define um df de teste\n",
    "    dfJuntoTeste = dfJunto\n",
    "\n",
    "    # Faz os calculos das probabilidades\n",
    "    dfJuntoTeste['aparicoesFalsas'] = dfJunto['aparicoesFalsas'] / (nFalsa + tFalsas)\n",
    "    dfJuntoTeste['aparicoesReais'] = dfJunto['aparicoesReais'] / (nReal + tReais)\n",
    "\n",
    "    # Pega o log na base 10\n",
    "    dfJuntoTeste['aparicoesFalsas'] = np.log10(dfJuntoTeste['aparicoesFalsas'])\n",
    "    dfJuntoTeste['aparicoesReais'] = np.log10(dfJuntoTeste['aparicoesReais'])\n",
    "\n",
    "    # NOTICIA:\n",
    "    \n",
    "    indices = ['fF', 'fR', 'rF', 'rR']\n",
    "    dfDados = pd.DataFrame(0, index=indices, columns=['num'])\n",
    "\n",
    "    for i in range (len(noticiasTeste)):\n",
    "        noticia = noticiasTeste.iloc[i, 1]\n",
    "        tag = noticiasTeste.iloc[i, 0]\n",
    "\n",
    "        # Cria um df com a notícia limpa\n",
    "        dfNoticia = pd.DataFrame(data = noticia, columns=['palavra'])\n",
    "\n",
    "        # Junta o df da noticia com o das probabilidades\n",
    "        dfNoticia = dfNoticia.merge(dfJuntoTeste, how='inner', left_on='palavra', right_on='palavras')\n",
    "\n",
    "        # Faz a soma das probabilidades\n",
    "        iFalsa = dfNoticia['aparicoesFalsas'].sum()\n",
    "        iReal = dfNoticia['aparicoesReais'].sum()\n",
    "\n",
    "        # Confere o resultado\n",
    "        if (iFalsa > iReal): # Falsa\n",
    "            resultado = 'F'\n",
    "        else:\n",
    "            resultado = 'R'\n",
    "            \n",
    "        chave = tag + resultado\n",
    "        dfDados.loc[chave, 'num'] += 1\n",
    "    \n",
    "    acuracia = round(float((dfDados.loc['fF', 'num'] + dfDados.loc['rR', 'num']) / dfDados['num'].sum()), 4)\n",
    "    \n",
    "    sensiReal = round(float(dfDados.loc['rR', 'num'] / (dfDados.loc['rR', 'num'] + dfDados.loc['rF', 'num'])), 4)\n",
    "    sensiFalsa = round(float(dfDados.loc['fF', 'num'] / (dfDados.loc['fF', 'num'] + dfDados.loc['fR', 'num'])), 4)\n",
    "    \n",
    "    precReal = round(float(dfDados.loc['rR', 'num'] / (dfDados.loc['rR', 'num'] + dfDados.loc['fR', 'num'])), 4)\n",
    "    precFalsa = round(float(dfDados.loc['fF', 'num'] / (dfDados.loc['fF', 'num'] + dfDados.loc['rF', 'num'])), 4)\n",
    "    \n",
    "    return acuracia, sensiReal, precReal, sensiFalsa, precFalsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularDPMedia(dados):\n",
    "    n = len(dados)\n",
    "    media = sum(dados) / n\n",
    "\n",
    "    somaDiferencaQuadrados = 0\n",
    "\n",
    "    for valor in dados:\n",
    "        diferenca = valor - media\n",
    "        somaDiferencaQuadrados += diferenca ** 2\n",
    "\n",
    "    vAmostral = somaDiferencaQuadrados / (n-1)\n",
    "    dp = vAmostral ** 0.5\n",
    "    return dp, media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularIntervaloConfianca(dp, media, n):\n",
    "    min = media - (1.96 * dp) / n ** 0.5\n",
    "    max = media + (1.96 * dp) / n ** 0.5\n",
    "    return min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias = []\n",
    "sensisReais = []\n",
    "sensisFalsas = []\n",
    "precsReais = []\n",
    "precsFalsas = []\n",
    "\n",
    "\n",
    "for i in range(36):\n",
    "    dfFalso = pd.read_json('../data/train/fakeTrain.json', orient='records', lines=True)\n",
    "    dfReal = pd.read_json('../data/train/realTrain.json', orient='records', lines=True)\n",
    "\n",
    "    [dfFalsoTeste, dfFalsoTreino] = separarTreinoTeste(dfFalso)\n",
    "    [dfRealTeste, dfRealTreino] = separarTreinoTeste(dfReal)\n",
    "\n",
    "    dfTestes = prepararDfTeste(dfFalsoTeste, dfRealTeste)\n",
    "    [dfFalsoTreino, dfRealTreino] = prepararDfsTreino(dfFalsoTreino, dfRealTreino)\n",
    "\n",
    "    [acuracia, sensiReal, precReal, sensiFalsa, precFalsa] = evaluate(dfRealTreino, dfFalsoTreino, dfTestes)\n",
    "\n",
    "    acuracias.append(acuracia)\n",
    "    sensisReais.append(sensiReal)\n",
    "    precsReais.append(precReal)\n",
    "\n",
    "    sensisFalsas.append(sensiFalsa)\n",
    "    precsFalsas.append(precFalsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpPrecFalsas, mediaPrecFalsas = calcularDPMedia(precsFalsas)\n",
    "minPrecisaoFalsas, maxPrecisaoFalsas = calcularIntervaloConfianca(dpPrecFalsas, mediaPrecFalsas, len(precsFalsas))\n",
    "\n",
    "dpPrecReais, mediaPrecFReais= calcularDPMedia(precsReais)\n",
    "minPrecisaoReais, maxPrecisaoReais = calcularIntervaloConfianca(dpPrecReais, mediaPrecFReais, len(precsReais))\n",
    "\n",
    "dpSensiReais, mediaSensiReais= calcularDPMedia(sensisReais)\n",
    "minSensiReais, maxSensiReais = calcularIntervaloConfianca(dpSensiReais, mediaSensiReais, len(sensisReais))\n",
    "\n",
    "dpSensiFalsas, mediaSensiFalsas= calcularDPMedia(sensisFalsas)\n",
    "minSensiFalsas, maxSensiFalsas = calcularIntervaloConfianca(dpSensiFalsas, mediaSensiFalsas, len(sensisFalsas))\n",
    "\n",
    "dpAcuracidade, mediaAcuracidade= calcularDPMedia(acuracias)\n",
    "minAcuracidade, maxAcuracidade = calcularIntervaloConfianca(dpAcuracidade, mediaAcuracidade, len(acuracias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métrica</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Máximo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precisão Falsas</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precisão Reais</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.8161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensibilidade Reais</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sensibilidade Falsas</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.7936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acuracidade</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>0.8920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Métrica  Mínimo  Máximo\n",
       "0       Precisão Falsas  1.0000  1.0000\n",
       "1        Precisão Reais  0.7959  0.8161\n",
       "2   Sensibilidade Reais  1.0000  1.0000\n",
       "3  Sensibilidade Falsas  0.7730  0.7936\n",
       "4           Acuracidade  0.8796  0.8920"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatar_porcentagem(valor):\n",
    "    return f\"{valor * 100:.2f}%\"\n",
    "\n",
    "dados = {\n",
    "    'Métrica': ['Precisão Falsas', 'Precisão Reais', 'Sensibilidade Reais', 'Sensibilidade Falsas', 'Acuracidade'],\n",
    "    'Mínimo': list([\n",
    "        minPrecisaoFalsas,\n",
    "        minPrecisaoReais,\n",
    "        minSensiReais,\n",
    "        minSensiFalsas,\n",
    "        minAcuracidade\n",
    "    ]),\n",
    "    'Máximo': list([\n",
    "        maxPrecisaoFalsas,\n",
    "        maxPrecisaoReais,\n",
    "        maxSensiReais,\n",
    "        maxSensiFalsas,\n",
    "        maxAcuracidade\n",
    "    ])\n",
    "}\n",
    "\n",
    "dfIntervalos = pd.DataFrame(dados)\n",
    "\n",
    "dfIntervalos['Mínimo'] = dfIntervalos['Mínimo'].round(4)\n",
    "dfIntervalos['Máximo'] = dfIntervalos['Máximo'].round(4)\n",
    "\n",
    "dfIntervalos"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

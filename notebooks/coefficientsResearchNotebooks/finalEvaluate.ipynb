{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separarTreinoTeste(dfA):\n",
    "    dfB = dfA\n",
    "    dfC = pd.DataFrame()\n",
    "    for i in range (len(dfA)):\n",
    "        vetor = dfA.iloc[i, 0]\n",
    "        if (rd.random() > 0.8): # vai p teste\n",
    "            dfB = pd.concat([dfB, pd.DataFrame(data=[[vetor]], columns=['noticias'])], ignore_index=True)\n",
    "        else:\n",
    "            dfC = pd.concat([dfC, pd.DataFrame(data=[[vetor]], columns=['noticias'])], ignore_index=True)\n",
    "\n",
    "    return dfB, dfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepararDfTeste (dfA, dfB):\n",
    "    # embaralha os dfs\n",
    "    dfEmbaralhado = pd.concat([dfA, dfB], ignore_index=True)\n",
    "    indices = list(dfEmbaralhado.index)\n",
    "    rd.shuffle(indices)\n",
    "    \n",
    "    tags = []\n",
    "    noticias = []\n",
    "\n",
    "    # cria uma coluna pra tag\n",
    "    for i in indices:\n",
    "        news = dfEmbaralhado.iloc[i, 0]\n",
    "        tags.append(news[0])\n",
    "        noticias.append(news[1:])\n",
    "\n",
    "    return pd.DataFrame({'tag': tags, 'noticia': noticias})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48552485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepararDfsTreino (dfF, dfR):\n",
    "    # Falsas\n",
    "    palavrasFalsas = []\n",
    "    for i in range(len(dfF)):\n",
    "        noticia = dfF.iloc[i,0][1:]\n",
    "        palavrasFalsas.extend(noticia)\n",
    "    dfF = pd.DataFrame({'palavras': palavrasFalsas})\n",
    "    dfF = dfF.groupby('palavras').size().reset_index(name='aparicoesFalsas')\n",
    "\n",
    "    palavrasFalsas = []\n",
    "    for i in range(len(dfR)):\n",
    "        noticia = dfR.iloc[i,0][1:]\n",
    "        palavrasFalsas.extend(noticia)\n",
    "    dfR = pd.DataFrame({'palavras': palavrasFalsas})\n",
    "    dfR = dfR.groupby('palavras').size().reset_index(name='aparicoesReais')\n",
    "    palavras = []\n",
    "\n",
    "    return dfF, dfR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dfReal, dfFalso, noticiasTeste, limiar, coeficiente):\n",
    "    # Junta os dataframes e une as palavras\n",
    "    dfJunto = dfReal.merge(dfFalso, how='outer')\n",
    "\n",
    "    # Conta quantas palavras tem em uma e não tem na outra\n",
    "    nReal = dfJunto.loc[dfJunto['aparicoesReais'].isna(), 'palavras'].count()\n",
    "    nFalsa = dfJunto.loc[dfJunto['aparicoesFalsas'].isna(), 'palavras'].count()\n",
    "\n",
    "    # Preenche as palavras que não aparecem com 1\n",
    "    dfJunto.fillna(1, inplace=True)\n",
    "\n",
    "    # Soma as palavras com 0 aparições com 1 para evitar multiplicação por 0\n",
    "    dfJunto.loc[dfJunto['aparicoesReais'] > 1, 'aparicoesReais'] += 1\n",
    "    dfJunto.loc[dfJunto['aparicoesFalsas'] > 1, 'aparicoesFalsas'] += 1\n",
    "\n",
    "    # Remove linhas onde a coluna 'palavras' é vazia ou só espaço\n",
    "    dfJunto = dfJunto[dfJunto['palavras'].str.strip() != '']\n",
    "\n",
    "    # Mantém só palavras que têm pelo menos uma letra (a–z ou A–Z ou acentuadas)\n",
    "    dfJunto = dfJunto[dfJunto['palavras'].str.match(r'^[A-Za-zÀ-ÖØ-öø-ÿ]+$', na=False)]\n",
    "\n",
    "    # Soma o total de aparições\n",
    "    totalReal = dfJunto['aparicoesReais'].sum()\n",
    "    totalFalso = dfJunto['aparicoesFalsas'].sum()\n",
    "\n",
    "    # Balanceia a ordem de grandeza das aparições\n",
    "    dfJunto['aparicoesFalsas'] *= totalReal / totalFalso\n",
    "    \n",
    "    # Faz o coeficiente de generalized jaccard\n",
    "    dfJunto['gj'] = np.minimum(dfJunto['aparicoesReais'], dfJunto['aparicoesFalsas']) / np.maximum(dfJunto['aparicoesReais'], dfJunto['aparicoesFalsas'])\n",
    "\n",
    "    # Faz o coeficiente de bray curtis\n",
    "    dfJunto['bc'] = abs(dfJunto['aparicoesReais'] - dfJunto['aparicoesFalsas']) / (dfJunto['aparicoesReais'] + dfJunto['aparicoesFalsas'])\n",
    "\n",
    "    # Limpa palavras com coeficiente menor que o limiar (palavras com aparições equivalentes em ambos casos)\n",
    "    if (coeficiente == 'bc'):\n",
    "        dfJunto = dfJunto.loc[dfJunto['bc'] > limiar]\n",
    "    elif (coeficiente == 'gj'):\n",
    "        dfJunto = dfJunto.loc[dfJunto['gj'] > limiar]\n",
    "\n",
    "    # Pega o total de aparições após NLP\n",
    "    tFalsas = dfJunto['aparicoesFalsas'].sum()\n",
    "    tReais = dfJunto['aparicoesReais'].sum()\n",
    "\n",
    "    # Define um df de teste\n",
    "    dfJuntoTeste = dfJunto\n",
    "\n",
    "    # Faz os calculos das probabilidades\n",
    "    dfJuntoTeste['aparicoesFalsas'] = dfJunto['aparicoesFalsas'] / (nFalsa + tFalsas)\n",
    "    dfJuntoTeste['aparicoesReais'] = dfJunto['aparicoesReais'] / (nReal + tReais)\n",
    "\n",
    "    # Pega o log na base 10\n",
    "    dfJuntoTeste['aparicoesFalsas'] = np.log10(dfJuntoTeste['aparicoesFalsas'])\n",
    "    dfJuntoTeste['aparicoesReais'] = np.log10(dfJuntoTeste['aparicoesReais'])\n",
    "\n",
    "    # NOTICIA:\n",
    "    \n",
    "    indices = ['fF', 'fR', 'rF', 'rR']\n",
    "    dfDados = pd.DataFrame(0, index=indices, columns=['num'])\n",
    "\n",
    "    for i in range (len(noticiasTeste)):\n",
    "        noticia = noticiasTeste.iloc[i, 1]\n",
    "        tag = noticiasTeste.iloc[i, 0]\n",
    "\n",
    "        # Cria um df com a notícia limpa\n",
    "        dfNoticia = pd.DataFrame(data = noticia, columns=['palavra'])\n",
    "\n",
    "        # Junta o df da noticia com o das probabilidades\n",
    "        dfNoticia = dfNoticia.merge(dfJuntoTeste, how='inner', left_on='palavra', right_on='palavras')\n",
    "\n",
    "        # Faz a soma das probabilidades\n",
    "        iFalsa = dfNoticia['aparicoesFalsas'].sum()\n",
    "        iReal = dfNoticia['aparicoesReais'].sum()\n",
    "\n",
    "        # Confere o resultado\n",
    "        if (iFalsa > iReal): # Falsa\n",
    "            resultado = 'F'\n",
    "        elif (iReal == iFalsa): # Empate\n",
    "            if (tag == 'f'):\n",
    "                resultado = 'R'\n",
    "            elif (tag == 'r'):\n",
    "                resultado = 'F'\n",
    "        else:\n",
    "            resultado = 'R'\n",
    "            \n",
    "        chave = tag + resultado\n",
    "        try:\n",
    "            dfDados.loc[chave, 'num'] += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return dfDados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1af3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bray curtis\n",
    "dfFalsoTreino = pd.read_json('../data/train/fakeTrain.json', orient='records', lines=True)\n",
    "dfRealTreino = pd.read_json('../data/train/realTrain.json', orient='records', lines=True)\n",
    "\n",
    "dfFalsoTeste = pd.read_json('../data/test/fakeTest.json', orient='records', lines=True) \n",
    "dfRealTeste = pd.read_json('../data/test/reakTest.json', orient='records', lines=True) \n",
    "\n",
    "dfTestes = prepararDfTeste(dfFalsoTeste, dfRealTeste)\n",
    "\n",
    "[dfFalsoTreino, dfRealTreino] = prepararDfsTreino(dfFalsoTreino, dfRealTreino)\n",
    "\n",
    "matrizesDeConfusao = [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]]\n",
    "matrizesRounds = []\n",
    "\n",
    "for i in range(1, 10): \n",
    "    limiar = i/10\n",
    "    print(limiar)\n",
    "    matrizDeConfusao = evaluate(dfRealTreino, dfFalsoTreino, dfTestes, limiar, 'bc')\n",
    "    matrizesRounds.append(matrizDeConfusao)\n",
    "\n",
    "for i in range(0, 9):\n",
    "    acuracidades = []\n",
    "    precisoesReais = []\n",
    "    precisoesFalsas = []\n",
    "    sensibilidadeReais = []\n",
    "    sensibilidadeFalsas = []\n",
    "    f1Reais = []\n",
    "    f1Falsas = []\n",
    "\n",
    "    for j in range(1, len(matrizesDeConfusao)):\n",
    "        acuracidade = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num'] + matrizesDeConfusao[j][i].loc['fF', 'num']) /\n",
    "            sum(matrizesDeConfusao[j][i]['num'])\n",
    "        ), 4)\n",
    "        acuracidades.append(acuracidade)\n",
    "\n",
    "        precReal = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num'] + matrizesDeConfusao[j][i].loc['fR', 'num'])\n",
    "        ), 4)\n",
    "        precisoesReais.append(precReal)\n",
    "\n",
    "        precFalsa = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num'] + matrizesDeConfusao[j][i].loc['rF', 'num'])\n",
    "        ), 4)\n",
    "        precisoesFalsas.append(precFalsa)\n",
    "\n",
    "        sensReal = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num'] + matrizesDeConfusao[j][i].loc['rF', 'num'])\n",
    "        ), 4)\n",
    "        sensibilidadeReais.append(sensReal)\n",
    "\n",
    "        sensFalsa = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num'] + matrizesDeConfusao[j][i].loc['fR', 'num'])\n",
    "        ), 4)\n",
    "        sensibilidadeFalsas.append(sensFalsa)\n",
    "\n",
    "        f1Real = round(2 * ((precReal * sensReal) / (precReal + sensReal)), 4)\n",
    "        f1Reais.append(f1Real)\n",
    "\n",
    "        f1Falsa = round(2 * ((precFalsa * sensFalsa) / (precFalsa + sensFalsa)), 4)\n",
    "        f1Falsas.append(f1Falsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76016389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized Jaccard\n",
    "dfFalsoTreino = pd.read_json('../data/train/fakeTrain.json', orient='records', lines=True)\n",
    "dfRealTreino = pd.read_json('../data/train/realTrain.json', orient='records', lines=True)\n",
    "\n",
    "dfFalsoTeste = pd.read_json('../data/test/fakeTest.json', orient='records', lines=True) \n",
    "dfRealTeste = pd.read_json('../data/test/reakTest.json', orient='records', lines=True) \n",
    "\n",
    "dfTestes = prepararDfTeste(dfFalsoTeste, dfRealTeste)\n",
    "\n",
    "[dfFalsoTreino, dfRealTreino] = prepararDfsTreino(dfFalsoTreino, dfRealTreino)\n",
    "\n",
    "matrizesDeConfusao = [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]]\n",
    "matrizesRounds = []\n",
    "\n",
    "for i in range(1, 10): \n",
    "    limiar = i/10\n",
    "    print(limiar)\n",
    "    matrizDeConfusao = evaluate(dfRealTreino, dfFalsoTreino, dfTestes, limiar, 'gj')\n",
    "    matrizesRounds.append(matrizDeConfusao)\n",
    "\n",
    "for i in range(0, 9):\n",
    "    acuracidades = []\n",
    "    precisoesReais = []\n",
    "    precisoesFalsas = []\n",
    "    sensibilidadeReais = []\n",
    "    sensibilidadeFalsas = []\n",
    "    f1Reais = []\n",
    "    f1Falsas = []\n",
    "\n",
    "    for j in range(1, len(matrizesDeConfusao)):\n",
    "        acuracidade = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num'] + matrizesDeConfusao[j][i].loc['fF', 'num']) /\n",
    "            sum(matrizesDeConfusao[j][i]['num'])\n",
    "        ), 4)\n",
    "        acuracidades.append(acuracidade)\n",
    "\n",
    "        precReal = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num'] + matrizesDeConfusao[j][i].loc['fR', 'num'])\n",
    "        ), 4)\n",
    "        precisoesReais.append(precReal)\n",
    "\n",
    "        precFalsa = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num'] + matrizesDeConfusao[j][i].loc['rF', 'num'])\n",
    "        ), 4)\n",
    "        precisoesFalsas.append(precFalsa)\n",
    "\n",
    "        sensReal = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['rR', 'num'] + matrizesDeConfusao[j][i].loc['rF', 'num'])\n",
    "        ), 4)\n",
    "        sensibilidadeReais.append(sensReal)\n",
    "\n",
    "        sensFalsa = round(float(\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num']) /\n",
    "            (matrizesDeConfusao[j][i].loc['fF', 'num'] + matrizesDeConfusao[j][i].loc['fR', 'num'])\n",
    "        ), 4)\n",
    "        sensibilidadeFalsas.append(sensFalsa)\n",
    "\n",
    "        f1Real = round(2 * ((precReal * sensReal) / (precReal + sensReal)), 4)\n",
    "        f1Reais.append(f1Real)\n",
    "\n",
    "        f1Falsa = round(2 * ((precFalsa * sensFalsa) / (precFalsa + sensFalsa)), 4)\n",
    "        f1Falsas.append(f1Falsa)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
